{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE DATABASE IF NOT EXISTS plants\n",
    "          LOCATION \"/user/yashiro/plants/\"\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS plants.subkingdoms(\n",
    "    id BIGINT,\n",
    "    link STRING,\n",
    "    name STRING,\n",
    "    slug STRING\n",
    ")\n",
    "    STORED AS PARQUET\n",
    "    LOCATION \"/user/yashiro/plants/subkingdoms\"\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS plants.kingdoms(\n",
    "    id BIGINT ,\n",
    "    name STRING ,\n",
    "    slug STRING ,\n",
    "    subkingdoms array<\n",
    "          struct <\n",
    "             id: BIGINT,\n",
    "             link: STRING,\n",
    "             name: STRING,\n",
    "             slug: STRING\n",
    "           >\n",
    "     >\n",
    ")\n",
    "    STORED AS PARQUET\n",
    "    LOCATION \"plants/kingdoms\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS plants.divisions(\n",
    "    division_classes array<\n",
    "         struct<\n",
    "            id: BIGINT,\n",
    "            link: STRING,\n",
    "            name: STRING,\n",
    "            slug: STRING\n",
    "             >\n",
    "         >,\n",
    "    id BIGINT,\n",
    "    kingdom struct<\n",
    "        id: BIGINT,\n",
    "        link: STRING,\n",
    "        name: STRING,\n",
    "        slug: STRING\n",
    "         >,\n",
    "    name STRING,\n",
    "    slug STRING,\n",
    "    subkingdom struct<\n",
    "        id: BIGINT,\n",
    "        link: STRING,\n",
    "        name: STRING,\n",
    "        slug: STRING\n",
    "        >\n",
    ")\n",
    "    STORED AS PARQUET\n",
    "    LOCATION \"/user/yashiro/plants/divisions\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+\n",
      "|database|  tableName|isTemporary|\n",
      "+--------+-----------+-----------+\n",
      "|  plants|  divisions|      false|\n",
      "|  plants|   kingdoms|      false|\n",
      "|  plants|subkingdoms|      false|\n",
      "+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                     |comment|\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "|id                          |bigint                                                        |null   |\n",
      "|name                        |string                                                        |null   |\n",
      "|slug                        |string                                                        |null   |\n",
      "|subkingdoms                 |array<struct<id:bigint,link:string,name:string,slug:string>>  |null   |\n",
      "|                            |                                                              |       |\n",
      "|# Detailed Table Information|                                                              |       |\n",
      "|Database                    |plants                                                        |       |\n",
      "|Table                       |kingdoms                                                      |       |\n",
      "|Owner                       |yashiro                                                       |       |\n",
      "|Created Time                |Tue May 26 23:30:44 EDT 2020                                  |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                  |       |\n",
      "|Created By                  |Spark 2.4.5                                                   |       |\n",
      "|Type                        |EXTERNAL                                                      |       |\n",
      "|Provider                    |hive                                                          |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1590550244]                            |       |\n",
      "|Location                    |hdfs://localhost:9000/user/yashiro/plants/kingdoms            |       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe   |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|       |\n",
      "|Storage Properties          |[serialization.format=1]                                      |       |\n",
      "+----------------------------+--------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FORMATTED kingdoms\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/26 23:39:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 3 items\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:30 /user/yashiro/kingdoms\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-16 17:51 /user/yashiro/lr1.model\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:32 /user/yashiro/plants\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/yashiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/26 23:40:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rmdir /user/yashiro/kingdoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/26 23:40:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-16 17:51 /user/yashiro/lr1.model\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:32 /user/yashiro/plants\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/yashiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/26 23:40:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /user/yashiro/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !hdfs dfs -copyFromLocal 00_input/data/* /user/yashiro/plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/26 23:42:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Configured Capacity: 250685575168 (233.47 GB)\n",
      "Present Capacity: 29408750441 (27.39 GB)\n",
      "DFS Remaining: 29395537920 (27.38 GB)\n",
      "DFS Used: 13212521 (12.60 MB)\n",
      "DFS Used%: 0.04%\n",
      "Under replicated blocks: 0\n",
      "Blocks with corrupt replicas: 0\n",
      "Missing blocks: 0\n",
      "Missing blocks (with replication factor 1): 0\n",
      "Pending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (1):\n",
      "\n",
      "Name: 127.0.0.1:50010 (localhost)\n",
      "Hostname: 10.0.0.111\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 250685575168 (233.47 GB)\n",
      "DFS Used: 13212521 (12.60 MB)\n",
      "Non DFS Used: 206186669207 (192.03 GB)\n",
      "DFS Remaining: 29395537920 (27.38 GB)\n",
      "DFS Used%: 0.01%\n",
      "DFS Remaining%: 11.73%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 2\n",
      "Last contact: Tue May 26 23:42:43 EDT 2020\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_df = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .json(f\"file://{BASE_DIR}/00_input/data/subkingdoms*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------+-------------+\n",
      "| id|                link|         name|         slug|\n",
      "+---+--------------------+-------------+-------------+\n",
      "|  1|http://trefle.io/...|Tracheobionta|tracheobionta|\n",
      "+---+--------------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sk_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_df.write.mode(\"append\").insertInto(\"plants.subkingdoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_df = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .json(f\"file://{BASE_DIR}/00_input/data/divisions*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_df.write.mode(\"append\").insertInto(\"plants.divisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       9|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM plants.divisions\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+-------------+-------------+--------------------+\n",
      "|    division_classes| id|             kingdom|         name|         slug|          subkingdom|\n",
      "+--------------------+---+--------------------+-------------+-------------+--------------------+\n",
      "|[[1, http://trefl...|  1|[1, http://trefle...|Magnoliophyta|magnoliophyta|[1, http://trefle...|\n",
      "|[[2, http://trefl...|  2|[1, http://trefle...|Coniferophyta|coniferophyta|[1, http://trefle...|\n",
      "|[[8, http://trefl...|  3|[1, http://trefle...| Pteridophyta| pteridophyta|[1, http://trefle...|\n",
      "+--------------------+---+--------------------+-------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM plants.divisions LIMIT 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_tables.sql\r\n"
     ]
    }
   ],
   "source": [
    "ls SparkHiveExample/hql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/yashiro/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/yashiro/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark-2.4.5-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.datastax.spark#spark-cassandra-connector_2.11 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f88beca0-b3d3-49b6-a0b4-b182675215c5;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.11;2.5.0 in spark-list\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.11;2.5.0 in spark-list\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.5.0 in spark-list\n",
      "\tfound com.datastax.oss#native-protocol;1.4.9 in spark-list\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre in spark-list\n",
      "\tfound com.typesafe#config;1.3.4 in spark-list\n",
      "\tfound com.github.jnr#jnr-ffi;2.1.10 in spark-list\n",
      "\tfound com.github.jnr#jffi;1.2.19 in spark-list\n",
      "\tfound org.ow2.asm#asm;7.1 in spark-list\n",
      "\tfound org.ow2.asm#asm-commons;7.1 in spark-list\n",
      "\tfound org.ow2.asm#asm-tree;7.1 in spark-list\n",
      "\tfound org.ow2.asm#asm-analysis;7.1 in spark-list\n",
      "\tfound org.ow2.asm#asm-util;7.1 in spark-list\n",
      "\tfound com.github.jnr#jnr-a64asm;1.0.0 in spark-list\n",
      "\tfound com.github.jnr#jnr-x86asm;1.0.2 in spark-list\n",
      "\tfound com.github.jnr#jnr-posix;3.0.50 in spark-list\n",
      "\tfound com.github.jnr#jnr-constants;0.9.12 in spark-list\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in spark-list\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.0.5 in spark-list\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.11 in spark-list\n",
      "\tfound org.apache.tinkerpop#gremlin-core;3.4.5 in spark-list\n",
      "\tfound org.apache.tinkerpop#gremlin-shaded;3.4.5 in spark-list\n",
      "\tfound commons-configuration#commons-configuration;1.10 in spark-list\n",
      "\tfound commons-lang#commons-lang;2.6 in spark-list\n",
      "\tfound commons-collections#commons-collections;3.2.2 in spark-list\n",
      "\tfound org.yaml#snakeyaml;1.15 in spark-list\n",
      "\tfound org.javatuples#javatuples;1.2 in spark-list\n",
      "\tfound com.carrotsearch#hppc;0.7.1 in spark-list\n",
      "\tfound com.jcabi#jcabi-manifests;1.1 in spark-list\n",
      "\tfound com.jcabi#jcabi-log;0.14 in spark-list\n",
      "\tfound com.squareup#javapoet;1.11.1 in central\n",
      "\tfound net.objecthunter#exp4j;0.4.8 in spark-list\n",
      "\tfound org.slf4j#jcl-over-slf4j;1.7.25 in spark-list\n",
      "\tfound org.apache.tinkerpop#gremlin-driver;3.4.5 in spark-list\n",
      "\tfound org.codehaus.groovy#groovy;2.5.7 in spark-list\n",
      "\tfound org.codehaus.groovy#groovy-json;2.5.7 in spark-list\n",
      "\tfound org.apache.tinkerpop#tinkergraph-gremlin;3.4.5 in spark-list\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.2 in spark-list\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in spark-list\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in spark-list\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in spark-list\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.5.0 in spark-list\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.5.0 in spark-list\n",
      "\tfound org.apache.commons#commons-lang3;3.5 in spark-list\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in spark-list\n",
      "\tfound com.typesafe.scala-logging#scala-logging_2.11;3.5.0 in spark-list\n",
      "\tfound org.scala-lang#scala-reflect;2.11.12 in central\n",
      ":: resolution report :: resolve 860ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\tcom.carrotsearch#hppc;0.7.1 from spark-list in [default]\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.5.0 from spark-list in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.5.0 from spark-list in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.5.0 from spark-list in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre from spark-list in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.4.9 from spark-list in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.11;2.5.0 from spark-list in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.11;2.5.0 from spark-list in [default]\n",
      "\tcom.github.jnr#jffi;1.2.19 from spark-list in [default]\n",
      "\tcom.github.jnr#jnr-a64asm;1.0.0 from spark-list in [default]\n",
      "\tcom.github.jnr#jnr-constants;0.9.12 from spark-list in [default]\n",
      "\tcom.github.jnr#jnr-ffi;2.1.10 from spark-list in [default]\n",
      "\tcom.github.jnr#jnr-posix;3.0.50 from spark-list in [default]\n",
      "\tcom.github.jnr#jnr-x86asm;1.0.2 from spark-list in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from spark-list in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from spark-list in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from spark-list in [default]\n",
      "\tcom.jcabi#jcabi-log;0.14 from spark-list in [default]\n",
      "\tcom.jcabi#jcabi-manifests;1.1 from spark-list in [default]\n",
      "\tcom.squareup#javapoet;1.11.1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from spark-list in [default]\n",
      "\tcom.typesafe#config;1.3.4 from spark-list in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging_2.11;3.5.0 from spark-list in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from spark-list in [default]\n",
      "\tcommons-configuration#commons-configuration;1.10 from spark-list in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from spark-list in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.0.5 from spark-list in [default]\n",
      "\tnet.objecthunter#exp4j;0.4.8 from spark-list in [default]\n",
      "\torg.apache.commons#commons-lang3;3.5 from spark-list in [default]\n",
      "\torg.apache.tinkerpop#gremlin-core;3.4.5 from spark-list in [default]\n",
      "\torg.apache.tinkerpop#gremlin-driver;3.4.5 from spark-list in [default]\n",
      "\torg.apache.tinkerpop#gremlin-shaded;3.4.5 from spark-list in [default]\n",
      "\torg.apache.tinkerpop#tinkergraph-gremlin;3.4.5 from spark-list in [default]\n",
      "\torg.codehaus.groovy#groovy;2.5.7 from spark-list in [default]\n",
      "\torg.codehaus.groovy#groovy-json;2.5.7 from spark-list in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.11 from spark-list in [default]\n",
      "\torg.javatuples#javatuples;1.2 from spark-list in [default]\n",
      "\torg.ow2.asm#asm;7.1 from spark-list in [default]\n",
      "\torg.ow2.asm#asm-analysis;7.1 from spark-list in [default]\n",
      "\torg.ow2.asm#asm-commons;7.1 from spark-list in [default]\n",
      "\torg.ow2.asm#asm-tree;7.1 from spark-list in [default]\n",
      "\torg.ow2.asm#asm-util;7.1 from spark-list in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.2 from spark-list in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.12 from central in [default]\n",
      "\torg.slf4j#jcl-over-slf4j;1.7.25 from spark-list in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from spark-list in [default]\n",
      "\torg.yaml#snakeyaml;1.15 from spark-list in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.commons#commons-lang3;3.8.1 by [org.apache.commons#commons-lang3;3.5] in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.8 by [org.scala-lang#scala-reflect;2.11.12] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 by [org.slf4j#slf4j-api;1.7.26] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   50  |   0   |   0   |   3   ||   47  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f88beca0-b3d3-49b6-a0b4-b182675215c5\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 47 already retrieved (0kB/15ms)\n",
      "20/05/27 00:00:54 WARN util.Utils: Your hostname, Yashiros-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.111 instead (on interface en0)\n",
      "20/05/27 00:00:54 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "20/05/27 00:00:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "20/05/27 00:00:56 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore\n",
      "20/05/27 00:00:56 INFO metastore.ObjectStore: ObjectStore, initialize called\n",
      "20/05/27 00:00:56 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored\n",
      "20/05/27 00:00:56 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored\n",
      "20/05/27 00:00:56 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=\"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/27 00:00:57 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n",
      "20/05/27 00:00:57 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n",
      "20/05/27 00:00:57 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n",
      "20/05/27 00:00:57 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n",
      "20/05/27 00:00:58 INFO DataNucleus.Query: Reading in results for query \"org.datanucleus.store.rdbms.query.SQLQuery@0\" since the connection used is closing\n",
      "20/05/27 00:00:58 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY\n",
      "20/05/27 00:00:58 INFO metastore.ObjectStore: Initialized ObjectStore\n",
      "20/05/27 00:00:58 INFO metastore.HiveMetaStore: Added admin role in metastore\n",
      "20/05/27 00:00:58 INFO metastore.HiveMetaStore: Added public role in metastore\n",
      "20/05/27 00:00:58 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty\n",
      "20/05/27 00:00:58 INFO metastore.HiveMetaStore: 0: get_all_databases\n",
      "20/05/27 00:00:58 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_all_databases\t\n",
      "20/05/27 00:00:58 INFO metastore.HiveMetaStore: 0: get_functions: db=default pat=*\n",
      "20/05/27 00:00:58 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_functions: db=default pat=*\t\n",
      "20/05/27 00:00:58 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MResourceUri\" is tagged as \"embedded-only\" so does not have its own datastore table.\n",
      "20/05/27 00:00:58 INFO session.SessionState: Created local directory: /var/folders/03/dtgfqq9d3kz5ftw13r818m980000gn/T/5cc57b4c-ada7-4ae7-8b47-e0f64ae10107_resources\n",
      "20/05/27 00:00:58 INFO session.SessionState: Created HDFS directory: /tmp/hive/yashiro/5cc57b4c-ada7-4ae7-8b47-e0f64ae10107\n",
      "20/05/27 00:00:58 INFO session.SessionState: Created local directory: /var/folders/03/dtgfqq9d3kz5ftw13r818m980000gn/T/yashiro/5cc57b4c-ada7-4ae7-8b47-e0f64ae10107\n",
      "20/05/27 00:00:58 INFO session.SessionState: Created HDFS directory: /tmp/hive/yashiro/5cc57b4c-ada7-4ae7-8b47-e0f64ae10107/_tmp_space.db\n",
      "20/05/27 00:00:58 INFO spark.SparkContext: Running Spark version 2.4.5\n",
      "20/05/27 00:00:58 INFO spark.SparkContext: Submitted application: SparkSQL::10.0.0.111\n",
      "20/05/27 00:00:58 INFO spark.SecurityManager: Changing view acls to: yashiro\n",
      "20/05/27 00:00:58 INFO spark.SecurityManager: Changing modify acls to: yashiro\n",
      "20/05/27 00:00:58 INFO spark.SecurityManager: Changing view acls groups to: \n",
      "20/05/27 00:00:58 INFO spark.SecurityManager: Changing modify acls groups to: \n",
      "20/05/27 00:00:58 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yashiro); groups with view permissions: Set(); users  with modify permissions: Set(yashiro); groups with modify permissions: Set()\n",
      "20/05/27 00:00:59 INFO util.Utils: Successfully started service 'sparkDriver' on port 54884.\n",
      "20/05/27 00:00:59 INFO spark.SparkEnv: Registering MapOutputTracker\n",
      "20/05/27 00:00:59 INFO spark.SparkEnv: Registering BlockManagerMaster\n",
      "20/05/27 00:00:59 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "20/05/27 00:00:59 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "20/05/27 00:00:59 INFO storage.DiskBlockManager: Created local directory at /private/var/folders/03/dtgfqq9d3kz5ftw13r818m980000gn/T/blockmgr-a8bb0ad8-79a9-479c-a8f7-85672d6a8a2c\n",
      "20/05/27 00:00:59 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB\n",
      "20/05/27 00:00:59 INFO spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "20/05/27 00:00:59 INFO util.log: Logging initialized @6159ms\n",
      "20/05/27 00:00:59 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\n",
      "20/05/27 00:00:59 INFO server.Server: Started @6232ms\n",
      "20/05/27 00:00:59 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "20/05/27 00:00:59 INFO server.AbstractConnector: Started ServerConnector@7c3c453b{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}\n",
      "20/05/27 00:00:59 INFO util.Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@628ba266{/jobs,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@595fed99{/jobs/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7d522180{/jobs/job,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@790654d5{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f935d49{/stages,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3321291a{/stages/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3dc46f24{/stages/stage,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@9c0d0bd{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@176333ee{/stages/pool,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18e6b72b{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@316d30ad{/storage,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3ea75b05{/storage/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30d5e37c{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1da745a2{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4597e6e3{/environment,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41ece227{/environment/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5e3d2765{/executors,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7910f355{/executors/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34ab26a{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@259195fe{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@12209826{/static,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47eaf55c{/,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c0798bd{/api,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@774f2992{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@602298b{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.0.111:4041\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.11-2.5.0.jar at spark://10.0.0.111:54884/jars/com.datastax.spark_spark-cassandra-connector_2.11-2.5.0.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.11-2.5.0.jar at spark://10.0.0.111:54884/jars/com.datastax.spark_spark-cassandra-connector-driver_2.11-2.5.0.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.5.0.jar at spark://10.0.0.111:54884/jars/com.datastax.oss_java-driver-core-shaded-4.5.0.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.5.0.jar at spark://10.0.0.111:54884/jars/com.datastax.oss_java-driver-mapper-runtime-4.5.0.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.apache.commons_commons-lang3-3.5.jar at spark://10.0.0.111:54884/jars/org.apache.commons_commons-lang3-3.5.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://10.0.0.111:54884/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.typesafe.scala-logging_scala-logging_2.11-3.5.0.jar at spark://10.0.0.111:54884/jars/com.typesafe.scala-logging_scala-logging_2.11-3.5.0.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://10.0.0.111:54884/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1590552059441\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.oss_native-protocol-1.4.9.jar at spark://10.0.0.111:54884/jars/com.datastax.oss_native-protocol-1.4.9.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre.jar at spark://10.0.0.111:54884/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.typesafe_config-1.3.4.jar at spark://10.0.0.111:54884/jars/com.typesafe_config-1.3.4.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jnr-ffi-2.1.10.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jnr-ffi-2.1.10.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jnr-posix-3.0.50.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jnr-posix-3.0.50.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at spark://10.0.0.111:54884/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar at spark://10.0.0.111:54884/jars/io.dropwizard.metrics_metrics-core-4.0.5.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar at spark://10.0.0.111:54884/jars/org.hdrhistogram_HdrHistogram-2.1.11.jar with timestamp 1590552059442\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.apache.tinkerpop_gremlin-core-3.4.5.jar at spark://10.0.0.111:54884/jars/org.apache.tinkerpop_gremlin-core-3.4.5.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.apache.tinkerpop_gremlin-driver-3.4.5.jar at spark://10.0.0.111:54884/jars/org.apache.tinkerpop_gremlin-driver-3.4.5.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.apache.tinkerpop_tinkergraph-gremlin-3.4.5.jar at spark://10.0.0.111:54884/jars/org.apache.tinkerpop_tinkergraph-gremlin-3.4.5.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.javatuples_javatuples-1.2.jar at spark://10.0.0.111:54884/jars/org.javatuples_javatuples-1.2.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.2.jar at spark://10.0.0.111:54884/jars/org.reactivestreams_reactive-streams-1.0.2.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://10.0.0.111:54884/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://10.0.0.111:54884/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jffi-1.2.19.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jffi-1.2.19.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.ow2.asm_asm-7.1.jar at spark://10.0.0.111:54884/jars/org.ow2.asm_asm-7.1.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.ow2.asm_asm-commons-7.1.jar at spark://10.0.0.111:54884/jars/org.ow2.asm_asm-commons-7.1.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.ow2.asm_asm-analysis-7.1.jar at spark://10.0.0.111:54884/jars/org.ow2.asm_asm-analysis-7.1.jar with timestamp 1590552059443\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.ow2.asm_asm-tree-7.1.jar at spark://10.0.0.111:54884/jars/org.ow2.asm_asm-tree-7.1.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.ow2.asm_asm-util-7.1.jar at spark://10.0.0.111:54884/jars/org.ow2.asm_asm-util-7.1.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.github.jnr_jnr-constants-0.9.12.jar at spark://10.0.0.111:54884/jars/com.github.jnr_jnr-constants-0.9.12.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.apache.tinkerpop_gremlin-shaded-3.4.5.jar at spark://10.0.0.111:54884/jars/org.apache.tinkerpop_gremlin-shaded-3.4.5.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/commons-configuration_commons-configuration-1.10.jar at spark://10.0.0.111:54884/jars/commons-configuration_commons-configuration-1.10.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/commons-collections_commons-collections-3.2.2.jar at spark://10.0.0.111:54884/jars/commons-collections_commons-collections-3.2.2.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.yaml_snakeyaml-1.15.jar at spark://10.0.0.111:54884/jars/org.yaml_snakeyaml-1.15.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.carrotsearch_hppc-0.7.1.jar at spark://10.0.0.111:54884/jars/com.carrotsearch_hppc-0.7.1.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.jcabi_jcabi-manifests-1.1.jar at spark://10.0.0.111:54884/jars/com.jcabi_jcabi-manifests-1.1.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.squareup_javapoet-1.11.1.jar at spark://10.0.0.111:54884/jars/com.squareup_javapoet-1.11.1.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/net.objecthunter_exp4j-0.4.8.jar at spark://10.0.0.111:54884/jars/net.objecthunter_exp4j-0.4.8.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.slf4j_jcl-over-slf4j-1.7.25.jar at spark://10.0.0.111:54884/jars/org.slf4j_jcl-over-slf4j-1.7.25.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://10.0.0.111:54884/jars/commons-lang_commons-lang-2.6.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.jcabi_jcabi-log-0.14.jar at spark://10.0.0.111:54884/jars/com.jcabi_jcabi-log-0.14.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.codehaus.groovy_groovy-2.5.7.jar at spark://10.0.0.111:54884/jars/org.codehaus.groovy_groovy-2.5.7.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/org.codehaus.groovy_groovy-json-2.5.7.jar at spark://10.0.0.111:54884/jars/org.codehaus.groovy_groovy-json-2.5.7.jar with timestamp 1590552059444\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://10.0.0.111:54884/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1590552059445\n",
      "20/05/27 00:00:59 INFO spark.SparkContext: Added JAR file:///Users/yashiro/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.5.0.jar at spark://10.0.0.111:54884/jars/com.datastax.oss_java-driver-query-builder-4.5.0.jar with timestamp 1590552059445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/27 00:00:59 INFO executor.Executor: Starting executor ID driver on host localhost\n",
      "20/05/27 00:00:59 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54885.\n",
      "20/05/27 00:00:59 INFO netty.NettyBlockTransferService: Server created on 10.0.0.111:54885\n",
      "20/05/27 00:00:59 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "20/05/27 00:00:59 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.0.111, 54885, None)\n",
      "20/05/27 00:00:59 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.0.111:54885 with 366.3 MB RAM, BlockManagerId(driver, 10.0.0.111, 54885, None)\n",
      "20/05/27 00:00:59 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.0.111, 54885, None)\n",
      "20/05/27 00:00:59 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.0.111, 54885, None)\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@370a8b6e{/metrics/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/yashiro/Desktop/spark_examples/spark-warehouse').\n",
      "20/05/27 00:00:59 INFO internal.SharedState: Warehouse path is 'file:/Users/yashiro/Desktop/spark_examples/spark-warehouse'.\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79d49790{/SQL,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13dc6649{/SQL/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ffb0d10{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3982206a{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:00:59 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@538aa83f{/static/sql,null,AVAILABLE,@Spark}\n",
      "20/05/27 00:01:00 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\n",
      "20/05/27 00:01:00 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.\n",
      "20/05/27 00:01:00 INFO client.HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/Users/yashiro/Desktop/spark_examples/spark-warehouse\n",
      "20/05/27 00:01:00 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from /user/hive/warehouse to file:/Users/yashiro/Desktop/spark_examples/spark-warehouse\n",
      "20/05/27 00:01:00 INFO metastore.HiveMetaStore: 0: Shutting down the object store...\n",
      "20/05/27 00:01:00 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=Shutting down the object store...\t\n",
      "20/05/27 00:01:00 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.\n",
      "20/05/27 00:01:00 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=Metastore shutdown complete.\t\n",
      "20/05/27 00:01:00 INFO metastore.HiveMetaStore: 0: get_database: default\n",
      "20/05/27 00:01:00 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: default\t\n",
      "20/05/27 00:01:00 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore\n",
      "20/05/27 00:01:00 INFO metastore.ObjectStore: ObjectStore, initialize called\n",
      "20/05/27 00:01:00 INFO DataNucleus.Query: Reading in results for query \"org.datanucleus.store.rdbms.query.SQLQuery@0\" since the connection used is closing\n",
      "20/05/27 00:01:00 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY\n",
      "20/05/27 00:01:00 INFO metastore.ObjectStore: Initialized ObjectStore\n",
      "20/05/27 00:01:01 INFO codegen.CodeGenerator: Code generated in 132.259104 ms\n",
      "hivevar:db_path\t/user/yashiro/plants\n",
      "Time taken: 1.56 seconds, Fetched 1 row(s)\n",
      "20/05/27 00:01:01 INFO thriftserver.SparkSQLCLIDriver: Time taken: 1.56 seconds, Fetched 1 row(s)\n",
      "20/05/27 00:01:01 INFO metastore.HiveMetaStore: 0: get_database: global_temp\n",
      "20/05/27 00:01:01 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: global_temp\t\n",
      "20/05/27 00:01:01 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "20/05/27 00:01:01 INFO metastore.HiveMetaStore: 0: create_database: Database(name:plants, description:, locationUri:file:/Users/yashiro/Desktop/spark_examples/spark-warehouse/plants.db, parameters:{})\n",
      "20/05/27 00:01:01 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_database: Database(name:plants, description:, locationUri:file:/Users/yashiro/Desktop/spark_examples/spark-warehouse/plants.db, parameters:{})\t\n",
      "20/05/27 00:01:01 WARN metastore.ObjectStore: Failed to get database plants, returning NoSuchObjectException\n",
      "20/05/27 00:01:01 INFO common.FileUtils: Creating directory if it doesn't exist: file:/Users/yashiro/Desktop/spark_examples/spark-warehouse/plants.db\n",
      "Time taken: 0.177 seconds\n",
      "20/05/27 00:01:01 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.177 seconds\n",
      "20/05/27 00:01:01 INFO spark.ContextCleaner: Cleaned accumulator 0\n",
      "20/05/27 00:01:01 INFO spark.ContextCleaner: Cleaned accumulator 1\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=subkingdoms\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=subkingdoms\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=subkingdoms\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=subkingdoms\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:subkingdoms, dbName:plants, owner:yashiro, createTime:1590552061, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:link, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/subkingdoms, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:subkingdoms, dbName:plants, owner:yashiro, createTime:1590552061, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:link, type:string, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/subkingdoms, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/27 00:01:02 INFO hive.log: Updating table stats fast for subkingdoms\n",
      "20/05/27 00:01:02 INFO hive.log: Updated size of table subkingdoms to 0\n",
      "Time taken: 0.371 seconds\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.371 seconds\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=kingdoms\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=kingdoms\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=kingdoms\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=kingdoms\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:kingdoms, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdoms, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/kingdoms, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdoms\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:kingdoms, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdoms, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/kingdoms, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdoms\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\n",
      "20/05/27 00:01:02 INFO hive.log: Updating table stats fast for kingdoms\n",
      "20/05/27 00:01:02 INFO hive.log: Updated size of table kingdoms to 0\n",
      "Time taken: 0.045 seconds\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.045 seconds\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=divisions\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=divisions\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=divisions\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=divisions\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:divisions, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:division_classes, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/divisions, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"division_classes\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:divisions, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:division_classes, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/divisions, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"division_classes\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\n",
      "20/05/27 00:01:02 INFO hive.log: Updating table stats fast for divisions\n",
      "20/05/27 00:01:02 INFO hive.log: Updated size of table divisions to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.044 seconds\r\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.044 seconds\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=families\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=families\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=families\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=families\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:families, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:common_name, type:string, comment:null), FieldSchema(name:division, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division_class, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division_order, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:genuses, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/families, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"division\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division_class\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division_order\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"genuses\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:families, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:common_name, type:string, comment:null), FieldSchema(name:division, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division_class, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division_order, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:genuses, type:array<struct<id:bigint,link:string,name:string,slug:string>>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/families, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"division\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division_class\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division_order\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"genuses\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\r\n",
      "20/05/27 00:01:02 INFO hive.log: Updating table stats fast for families\r\n",
      "20/05/27 00:01:02 INFO hive.log: Updated size of table families to 0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.047 seconds\r\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.047 seconds\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=genuses\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=genuses\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=genuses\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=genuses\t\r\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:genuses, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:class, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:family, type:struct<common_name:string,id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:order, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/genuses, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"class\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"family\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"order\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\r\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:genuses, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:class, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:division, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:family, type:struct<common_name:string,id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:kingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:name, type:string, comment:null), FieldSchema(name:order, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null), FieldSchema(name:slug, type:string, comment:null), FieldSchema(name:subkingdom, type:struct<id:bigint,link:string,name:string,slug:string>, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/genuses, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"class\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"division\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"family\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"kingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"order\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"subkingdom\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\r\n",
      "20/05/27 00:01:02 INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://localhost:9000/user/yashiro/plants/genuses\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.066 seconds\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.066 seconds\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_database: plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_database: plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: get_table : db=plants tbl=plants\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=get_table : db=plants tbl=plants\t\n",
      "20/05/27 00:01:02 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:plants, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:common_name, type:string, comment:null), FieldSchema(name:complete_data, type:boolean, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:link, type:string, comment:null), FieldSchema(name:scientific_name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/plants, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"complete_data\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"scientific_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\n",
      "20/05/27 00:01:02 INFO HiveMetaStore.audit: ugi=yashiro\tip=unknown-ip-addr\tcmd=create_table: Table(tableName:plants, dbName:plants, owner:yashiro, createTime:1590552062, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:common_name, type:string, comment:null), FieldSchema(name:complete_data, type:boolean, comment:null), FieldSchema(name:id, type:bigint, comment:null), FieldSchema(name:link, type:string, comment:null), FieldSchema(name:scientific_name, type:string, comment:null), FieldSchema(name:slug, type:string, comment:null)], location:hdfs://localhost:9000/user/yashiro/plants/plants, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.part.0={\"type\":\"struct\",\"fields\":[{\"name\":\"common_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"complete_data\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"link\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"scientific_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"slug\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}, spark.sql.sources.schema.numParts=1, spark.sql.create.version=2.4.5}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null))\t\n",
      "20/05/27 00:01:02 INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://localhost:9000/user/yashiro/plants/plants\n",
      "Time taken: 0.048 seconds\n",
      "20/05/27 00:01:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.048 seconds\n",
      "20/05/27 00:01:02 INFO server.AbstractConnector: Stopped Spark@7c3c453b{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}\n",
      "20/05/27 00:01:02 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.0.111:4041\n",
      "20/05/27 00:01:02 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "20/05/27 00:01:02 INFO memory.MemoryStore: MemoryStore cleared\n",
      "20/05/27 00:01:02 INFO storage.BlockManager: BlockManager stopped\n",
      "20/05/27 00:01:02 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\n",
      "20/05/27 00:01:02 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "20/05/27 00:01:02 INFO spark.SparkContext: Successfully stopped SparkContext\n",
      "20/05/27 00:01:02 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "20/05/27 00:01:02 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/03/dtgfqq9d3kz5ftw13r818m980000gn/T/spark-accba02f-a082-4ed6-9967-1fdf861ed1a2\n",
      "20/05/27 00:01:02 INFO util.ShutdownHookManager: Deleting directory /private/var/folders/03/dtgfqq9d3kz5ftw13r818m980000gn/T/spark-80330d0b-8186-450a-9f0f-637ade955239\n"
     ]
    }
   ],
   "source": [
    "!spark-sql -f SparkHiveExample/hql/create_tables.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/05/27 00:08:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 6 items\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:49 /user/yashiro/plants/divisions\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:32 /user/yashiro/plants/families\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-27 00:01 /user/yashiro/plants/genuses\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:30 /user/yashiro/plants/kingdoms\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-27 00:01 /user/yashiro/plants/plants\n",
      "drwxr-xr-x   - yashiro supergroup          0 2020-05-26 23:47 /user/yashiro/plants/subkingdoms\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/yashiro/plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
