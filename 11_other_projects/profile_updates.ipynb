{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "base_path = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, col, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/speedy/Desktop/spark_examples'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = base_path + \"/00_input/_profiles_txt/file-0*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.read.text(\"file://\" + files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = data_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def count_text(text: str) -> int:\n",
    "    return len(text) - text.count(\" \")\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    less_space = re.sub(\"\\s\\s\", \" \", text.strip())\n",
    "    return \"\".join([char for char in text if char.isalnum() or char == \" \"]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd['text_len'] = data_pd['value'].apply(lambda x: count_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd['clear_text'] = data_pd['value'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>text_len</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Professional Summary</td>\n",
       "      <td>19</td>\n",
       "      <td>professional summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  value  text_len            clear_text\n",
       "0                               0                      \n",
       "1                               0                      \n",
       "2  Professional Summary        19  professional summary\n",
       "3                               0                      \n",
       "4                               0                      "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pd = data_pd[data_pd[\"text_len\"] > 20].drop_duplicates(subset=\"clear_text\", keep=\"first\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>text_len</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 years of experience in data engineering and...</td>\n",
       "      <td>60</td>\n",
       "      <td>10 years of experience in data engineering and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hadoop and RDBMS data pipelines, transformatio...</td>\n",
       "      <td>65</td>\n",
       "      <td>hadoop and rdbms data pipelines transformation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a variety of data processing and transformatio...</td>\n",
       "      <td>60</td>\n",
       "      <td>a variety of data processing and transformatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>▪ Performance tune Hadoop data systems and pi...</td>\n",
       "      <td>58</td>\n",
       "      <td>performance tune hadoop data systems and pip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>system configuration and processing using d...</td>\n",
       "      <td>62</td>\n",
       "      <td>system configuration and processing using d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                value  text_len  \\\n",
       "5   10 years of experience in data engineering and...        60   \n",
       "6   Hadoop and RDBMS data pipelines, transformatio...        65   \n",
       "7   a variety of data processing and transformatio...        60   \n",
       "11   ▪ Performance tune Hadoop data systems and pi...        58   \n",
       "12     system configuration and processing using d...        62   \n",
       "\n",
       "                                           clear_text  \n",
       "5   10 years of experience in data engineering and...  \n",
       "6   hadoop and rdbms data pipelines transformation...  \n",
       "7   a variety of data processing and transformatio...  \n",
       "11    performance tune hadoop data systems and pip...  \n",
       "12     system configuration and processing using d...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pd = filtered_pd[\"clear_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     10 years of experience in data engineering and...\n",
       "6     hadoop and rdbms data pipelines transformation...\n",
       "7     a variety of data processing and transformatio...\n",
       "11      performance tune hadoop data systems and pip...\n",
       "12       system configuration and processing using d...\n",
       "Name: clear_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.createDataFrame(filtered_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|clear_text                                                               |\n",
      "+-------------------------------------------------------------------------+\n",
      "|10 years of experience in data engineering and analytics working with    |\n",
      "|hadoop and rdbms data pipelines transformation and cleansing  skilled in |\n",
      "|a variety of data processing and transformation tools and data storage   |\n",
      "|  performance tune hadoop data systems and pipelines with optimized      |\n",
      "|   system configuration and processing using data processing tools hadoop|\n",
      "|   cycle apache camel apache flume kafka apatar clover and others        |\n",
      "|  worked with systems employing hive rdds dataframes                     |\n",
      "|  forensic analysis with large complex data sets using realtime          |\n",
      "|   analytics and distributed big data platforms                          |\n",
      "|  comfortable working with hadoop distributions cloudera cloudera        |\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_lines = new_df.select(\"clear_text\")\n",
    "profile_lines.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+\n",
      "|clear_text                                                            |\n",
      "+----------------------------------------------------------------------+\n",
      "|  forensic analysis with large complex data sets using realtime       |\n",
      "|     skilled in data analysis and forensic analysis using hadoop tools|\n",
      "|     skilled in forensic methods of data cleaning and refining data   |\n",
      "|     internal forensic incident response and threat hunting using sans|\n",
      "|candidate  gcfe  giac forensic examiner certification                 |\n",
      "+----------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_lines.filter(col(\"clear_text\").contains(\"forensic\")).show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_lines.filter(col(\"clear_text\").contains(\"airflow\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(clear_text='apache spark python sql oracle   cloudera hortonworks ms azure    '),\n",
       " Row(clear_text='      spark python and kinesis'),\n",
       " Row(clear_text='     wrote python scripts in jupyter to loop through daily dynamic'),\n",
       " Row(clear_text='     wrote python scripts in jupyter to pull information security logs'),\n",
       " Row(clear_text='     created python functions to parse cefformatted information security'),\n",
       " Row(clear_text='     integrated disparate versions of pythonspark to update older code'),\n",
       " Row(clear_text='     design and develop etl workflows using python and scala for processing'),\n",
       " Row(clear_text='     developed an automated employee access audit with powershell python'),\n",
       " Row(clear_text='     application logging development for elk stack with python for'),\n",
       " Row(clear_text='working extensively on hive sqoop pig and python'),\n",
       " Row(clear_text='creation of udf functions in python or scala'),\n",
       " Row(clear_text='technologies mapr hadoophdfs hive hbase spark pig java spring java ee java esb rest web services shell python'),\n",
       " Row(clear_text='design and develop etl workflows using python and scala for processing data in hdfs  mongodb'),\n",
       " Row(clear_text='involved in converting hivesql queries into spark transformations using spark rdds python and scala'),\n",
       " Row(clear_text='   programming experience in python and java and experience with data'),\n",
       " Row(clear_text='spark api avro scala python parquet orc microsoft powershell c c'),\n",
       " Row(clear_text='     designed and developed etl workflows using python and scala for'),\n",
       " Row(clear_text='python scala pig hive rdds dataframes'),\n",
       " Row(clear_text='      sql java python scala pig hive rdds dataframes  mapreduce'),\n",
       " Row(clear_text='      java hive ql mapreduce python scala sql html php unix shell')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_lines.filter(col(\"clear_text\").contains(\"python\")).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
